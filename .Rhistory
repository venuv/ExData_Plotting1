user_objects <- lookupUsers(unique_tweeter_names)
user_objects_df<-ldply(user_objects,function(t) t$toDataFrame())
curated_user_objects<- user_objects_df[(user_objects_df$followersCount>99)&(user_objects_df$followersCount/user_objects_df$friendsCount > 1),]
# save information about these curated tweeters in hashtag specific file
x <- toJSON(unname(split(curated_user_objects, 1:nrow(curated_user_objects))))
cat(x,file=hashtag_file)
dim(rdf)
library("twitteR")
library("wordcloud")
library("tm")
library(RColorBrewer)
library(plyr)
library(rjson)
rdf<- NULL
scr_names<-NULL
curated_user_objects <- NULL
dir <- "/Users/venuv/Desktop/WHS/Tweeter_DB"
hashtag_name <- "GameOfThrones"
hashtag_string<- paste("#",hashtag_name,sep='')
hashtag_file <- paste(dir,'/',hashtag_name,"_ht_tweeter_list.json",sep='')
## Boilerplate twitter_oauth : first time you get a prompt to cache session cookie
consumer_key <- "0IpI79mRPE3abAHrQKP8H0Z7E"
consumer_secret <- "E4EHnsQOb4BDQ7s8lTPlxWbr1guUv9F9QJBU2UmBeqwokdHJvY"
access_token <- "1202061-nzRRdJu8Ze9aEev4ZzjeORYfjvExpv6kY1Mu4RXZtB"
access_secret <- "6ElTLeMiI2JaF9NNxAUOsLZ5XyDRWJnpOXYYEEjb3RpGt"
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
## get a tweet corpus for show specific hashtag. can be regionalized to language, use ISO 639-1 code
r_show <- searchTwitter(hashtag_string,n=5000)
## convert list to dataFrame for easier manipulation
rdf <- ldply(r_show,function(t) t$toDataFrame())
## filter out a curated list of tweets
# Curation Filter to be refined, but the followint at present:
#   more than avg number of retweets
#   more followers than friends
# get tweeter screen names for tweeters with more than an average number of retweets
#rtmean<-mean(rdf$retweetCount)
#better_tweeters<-rdf[rdf$retweetCount>rtmean,]
#repeat_tweeters <- better_tweeters[duplicated(better_tweeters$screenName),]
repeat_tweeters <- rdf[duplicated(rdf$screenName),]
#fetch the user objects for Tweeters who have more followers than friends
scr_names<- repeat_tweeters$screenName
unique_tweeter_names <-unique(scr_names)
user_objects <- lookupUsers(unique_tweeter_names)
user_objects_df<-ldply(user_objects,function(t) t$toDataFrame())
curated_user_objects<- user_objects_df[(user_objects_df$followersCount>99)&(user_objects_df$followersCount/user_objects_df$friendsCount > 1),]
# save information about these curated tweeters in hashtag specific file
x <- toJSON(unname(split(curated_user_objects, 1:nrow(curated_user_objects))))
cat(x,file=hashtag_file)
dim(curated_user_objects)
curated_user_objects$followersCount
curated_user_objects$followersCount/curated_user_objects$friendsCount
library("twitteR")
library("wordcloud")
library("tm")
library(RColorBrewer)
library(plyr)
library(rjson)
rdf<- NULL
scr_names<-NULL
curated_user_objects <- NULL
dir <- "/Users/venuv/Desktop/WHS/Tweeter_DB"
hashtag_name <- "TBBT"
hashtag_string<- paste("#",hashtag_name,sep='')
hashtag_file <- paste(dir,'/',hashtag_name,"_ht_tweeter_list.json",sep='')
## Boilerplate twitter_oauth : first time you get a prompt to cache session cookie
consumer_key <- "0IpI79mRPE3abAHrQKP8H0Z7E"
consumer_secret <- "E4EHnsQOb4BDQ7s8lTPlxWbr1guUv9F9QJBU2UmBeqwokdHJvY"
access_token <- "1202061-nzRRdJu8Ze9aEev4ZzjeORYfjvExpv6kY1Mu4RXZtB"
access_secret <- "6ElTLeMiI2JaF9NNxAUOsLZ5XyDRWJnpOXYYEEjb3RpGt"
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
## get a tweet corpus for show specific hashtag. can be regionalized to language, use ISO 639-1 code
r_show <- searchTwitter(hashtag_string,n=5000)
## retweet removal code, in case needed
#r_show_noRT<-strip_retweets(r_show)
## convert list to dataFrame for easier manipulation
rdf <- ldply(r_show,function(t) t$toDataFrame())
## filter out a curated list of tweets
# Curation Filter to be refined, but the followint at present:
#   more than avg number of retweets
#   more followers than friends
# get tweeter screen names for tweeters with more than an average number of retweets
#rtmean<-mean(rdf$retweetCount)
#better_tweeters<-rdf[rdf$retweetCount>rtmean,]
#repeat_tweeters <- better_tweeters[duplicated(better_tweeters$screenName),]
repeat_tweeters <- rdf[duplicated(rdf$screenName),]
#fetch the user objects for Tweeters who have more followers than friends
scr_names<- repeat_tweeters$screenName
unique_tweeter_names <-unique(scr_names)
user_objects <- lookupUsers(unique_tweeter_names)
user_objects_df<-ldply(user_objects,function(t) t$toDataFrame())
curated_user_objects<- user_objects_df[(user_objects_df$followersCount>99)&(user_objects_df$followersCount/user_objects_df$friendsCount > 1),]
# save information about these curated tweeters in hashtag specific file
x <- toJSON(unname(split(curated_user_objects, 1:nrow(curated_user_objects))))
cat(x,file=hashtag_file)
curated_user_objects$followersCount
curated_user_objects$screenName
repeat_tweeters$text
library("twitteR")
library("wordcloud")
library("tm")
library(RColorBrewer)
library(plyr)
library(rjson)
rdf<- NULL
scr_names<-NULL
curated_user_objects <- NULL
dir <- "/Users/venuv/Desktop/WHS/Tweeter_DB"
hashtag_name <- "BigBangTheory"
hashtag_string<- paste("#",hashtag_name,sep='')
hashtag_file <- paste(dir,'/',hashtag_name,"_ht_tweeter_list.json",sep='')
## Boilerplate twitter_oauth : first time you get a prompt to cache session cookie
consumer_key <- "0IpI79mRPE3abAHrQKP8H0Z7E"
consumer_secret <- "E4EHnsQOb4BDQ7s8lTPlxWbr1guUv9F9QJBU2UmBeqwokdHJvY"
access_token <- "1202061-nzRRdJu8Ze9aEev4ZzjeORYfjvExpv6kY1Mu4RXZtB"
access_secret <- "6ElTLeMiI2JaF9NNxAUOsLZ5XyDRWJnpOXYYEEjb3RpGt"
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
## get a tweet corpus for show specific hashtag. can be regionalized to language, use ISO 639-1 code
r_show <- searchTwitter(hashtag_string,n=5000)
## retweet removal code, in case needed
#r_show_noRT<-strip_retweets(r_show)
## convert list to dataFrame for easier manipulation
rdf <- ldply(r_show,function(t) t$toDataFrame())
## filter out a curated list of tweets
# Curation Filter to be refined, but the followint at present:
#   more than avg number of retweets
#   more followers than friends
# get tweeter screen names for tweeters with more than an average number of retweets
#rtmean<-mean(rdf$retweetCount)
#better_tweeters<-rdf[rdf$retweetCount>rtmean,]
#repeat_tweeters <- better_tweeters[duplicated(better_tweeters$screenName),]
repeat_tweeters <- rdf[duplicated(rdf$screenName),]
#fetch the user objects for Tweeters who have more followers than friends
scr_names<- repeat_tweeters$screenName
unique_tweeter_names <-unique(scr_names)
user_objects <- lookupUsers(unique_tweeter_names)
user_objects_df<-ldply(user_objects,function(t) t$toDataFrame())
curated_user_objects<- user_objects_df[(user_objects_df$followersCount>99)&(user_objects_df$followersCount/user_objects_df$friendsCount > 1),]
# save information about these curated tweeters in hashtag specific file
x <- toJSON(unname(split(curated_user_objects, 1:nrow(curated_user_objects))))
cat(x,file=hashtag_file)
#use lookupUsers to get follower count for repeat_tweeters
#getUserObjects <- function(users) {
#    groups <- split(users, ceiling(seq_along(users)/6000))
#    userObjects <- ldply(groups, function(group) {
#        objects <- lookupUsers(group)
#        out <- twListToDF(objects)
#        print("Waiting for 15 Minutes...")
#        Sys.sleep(900)
#        return(out)
#    })
#    return(userObjects)
#}
#userObjects <- getUserObjects(userNames)
## experimental wordcloud to get a sense of Tweet content
r_show_txt <- repeat_tweeters$text
r_show_txt_corpus <- Corpus(VectorSource(r_show_txt))
r_show_txt_corpus <- tm_map(r_show_txt_corpus,
content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')),
mc.cores=1
)
r_show_txt_corpus <- tm_map(r_show_txt_corpus, content_transformer(tolower), mc.cores=1)
r_show_txt_corpus <- tm_map(r_show_txt_corpus, removePunctuation, mc.cores=1)
r_show_txt_corpus <- tm_map(r_show_txt_corpus, function(x)removeWords(x,stopwords()), mc.cores=1)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(r_show_txt_corpus,min.freq=1,max.words=100, random.order=T, colors=pal2)
curated_user_objects$followersCount
rdf<- NULL
scr_names<-NULL
curated_user_objects <- NULL
dir <- "/Users/venuv/Desktop/WHS/Tweeter_DB"
hashtag_name <- "NCIS"
hashtag_string<- paste("#",hashtag_name,sep='')
hashtag_file <- paste(dir,'/',hashtag_name,"_ht_tweeter_list.json",sep='')
## Boilerplate twitter_oauth : first time you get a prompt to cache session cookie
consumer_key <- "0IpI79mRPE3abAHrQKP8H0Z7E"
consumer_secret <- "E4EHnsQOb4BDQ7s8lTPlxWbr1guUv9F9QJBU2UmBeqwokdHJvY"
access_token <- "1202061-nzRRdJu8Ze9aEev4ZzjeORYfjvExpv6kY1Mu4RXZtB"
access_secret <- "6ElTLeMiI2JaF9NNxAUOsLZ5XyDRWJnpOXYYEEjb3RpGt"
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
## get a tweet corpus for show specific hashtag. can be regionalized to language, use ISO 639-1 code
r_show <- searchTwitter(hashtag_string,n=5000)
## retweet removal code, in case needed
#r_show_noRT<-strip_retweets(r_show)
## convert list to dataFrame for easier manipulation
rdf <- ldply(r_show,function(t) t$toDataFrame())
## filter out a curated list of tweets
# Curation Filter to be refined, but the followint at present:
#   more than avg number of retweets
#   more followers than friends
# get tweeter screen names for tweeters with more than an average number of retweets
#rtmean<-mean(rdf$retweetCount)
#better_tweeters<-rdf[rdf$retweetCount>rtmean,]
#repeat_tweeters <- better_tweeters[duplicated(better_tweeters$screenName),]
repeat_tweeters <- rdf[duplicated(rdf$screenName),]
#fetch the user objects for Tweeters who have more followers than friends
scr_names<- repeat_tweeters$screenName
unique_tweeter_names <-unique(scr_names)
user_objects <- lookupUsers(unique_tweeter_names)
user_objects_df<-ldply(user_objects,function(t) t$toDataFrame())
curated_user_objects<- user_objects_df[(user_objects_df$followersCount>99)&(user_objects_df$followersCount/user_objects_df$friendsCount > 1),]
# save information about these curated tweeters in hashtag specific file
x <- toJSON(unname(split(curated_user_objects, 1:nrow(curated_user_objects))))
cat(x,file=hashtag_file)
#use lookupUsers to get follower count for repeat_tweeters
#getUserObjects <- function(users) {
#    groups <- split(users, ceiling(seq_along(users)/6000))
#    userObjects <- ldply(groups, function(group) {
#        objects <- lookupUsers(group)
#        out <- twListToDF(objects)
#        print("Waiting for 15 Minutes...")
#        Sys.sleep(900)
#        return(out)
#    })
#    return(userObjects)
#}
#userObjects <- getUserObjects(userNames)
## experimental wordcloud to get a sense of Tweet content
r_show_txt <- repeat_tweeters$text
r_show_txt_corpus <- Corpus(VectorSource(r_show_txt))
r_show_txt_corpus <- tm_map(r_show_txt_corpus,
content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')),
mc.cores=1
)
r_show_txt_corpus <- tm_map(r_show_txt_corpus, content_transformer(tolower), mc.cores=1)
r_show_txt_corpus <- tm_map(r_show_txt_corpus, removePunctuation, mc.cores=1)
r_show_txt_corpus <- tm_map(r_show_txt_corpus, function(x)removeWords(x,stopwords()), mc.cores=1)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(r_show_txt_corpus,min.freq=1,max.words=100, random.order=T, colors=pal2)
curated_user_objects$followersCount
rdf<- NULL
scr_names<-NULL
curated_user_objects <- NULL
dir <- "/Users/venuv/Desktop/WHS/Tweeter_DB"
hashtag_name <- "AskScanda"
hashtag_string<- paste("#",hashtag_name,sep='')
hashtag_file <- paste(dir,'/',hashtag_name,"_ht_tweeter_list.json",sep='')
## Boilerplate twitter_oauth : first time you get a prompt to cache session cookie
consumer_key <- "0IpI79mRPE3abAHrQKP8H0Z7E"
consumer_secret <- "E4EHnsQOb4BDQ7s8lTPlxWbr1guUv9F9QJBU2UmBeqwokdHJvY"
access_token <- "1202061-nzRRdJu8Ze9aEev4ZzjeORYfjvExpv6kY1Mu4RXZtB"
access_secret <- "6ElTLeMiI2JaF9NNxAUOsLZ5XyDRWJnpOXYYEEjb3RpGt"
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
## get a tweet corpus for show specific hashtag. can be regionalized to language, use ISO 639-1 code
r_show <- searchTwitter(hashtag_string,n=5000)
## retweet removal code, in case needed
#r_show_noRT<-strip_retweets(r_show)
## convert list to dataFrame for easier manipulation
rdf <- ldply(r_show,function(t) t$toDataFrame())
## filter out a curated list of tweets
# Curation Filter to be refined, but the followint at present:
#   more than avg number of retweets
#   more followers than friends
# get tweeter screen names for tweeters with more than an average number of retweets
#rtmean<-mean(rdf$retweetCount)
#better_tweeters<-rdf[rdf$retweetCount>rtmean,]
#repeat_tweeters <- better_tweeters[duplicated(better_tweeters$screenName),]
repeat_tweeters <- rdf[duplicated(rdf$screenName),]
#fetch the user objects for Tweeters who have more followers than friends
scr_names<- repeat_tweeters$screenName
unique_tweeter_names <-unique(scr_names)
user_objects <- lookupUsers(unique_tweeter_names)
user_objects_df<-ldply(user_objects,function(t) t$toDataFrame())
curated_user_objects<- user_objects_df[(user_objects_df$followersCount>99)&(user_objects_df$followersCount/user_objects_df$friendsCount > 1),]
# save information about these curated tweeters in hashtag specific file
x <- toJSON(unname(split(curated_user_objects, 1:nrow(curated_user_objects))))
cat(x,file=hashtag_file)
rdf<- NULL
scr_names<-NULL
curated_user_objects <- NULL
dir <- "/Users/venuv/Desktop/WHS/Tweeter_DB"
hashtag_name <- "NCISLA"
hashtag_string<- paste("#",hashtag_name,sep='')
hashtag_file <- paste(dir,'/',hashtag_name,"_ht_tweeter_list.json",sep='')
## Boilerplate twitter_oauth : first time you get a prompt to cache session cookie
consumer_key <- "0IpI79mRPE3abAHrQKP8H0Z7E"
consumer_secret <- "E4EHnsQOb4BDQ7s8lTPlxWbr1guUv9F9QJBU2UmBeqwokdHJvY"
access_token <- "1202061-nzRRdJu8Ze9aEev4ZzjeORYfjvExpv6kY1Mu4RXZtB"
access_secret <- "6ElTLeMiI2JaF9NNxAUOsLZ5XyDRWJnpOXYYEEjb3RpGt"
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
## get a tweet corpus for show specific hashtag. can be regionalized to language, use ISO 639-1 code
r_show <- searchTwitter(hashtag_string,n=5000)
## retweet removal code, in case needed
#r_show_noRT<-strip_retweets(r_show)
## convert list to dataFrame for easier manipulation
rdf <- ldply(r_show,function(t) t$toDataFrame())
## filter out a curated list of tweets
# Curation Filter to be refined, but the followint at present:
#   more than avg number of retweets
#   more followers than friends
# get tweeter screen names for tweeters with more than an average number of retweets
#rtmean<-mean(rdf$retweetCount)
#better_tweeters<-rdf[rdf$retweetCount>rtmean,]
#repeat_tweeters <- better_tweeters[duplicated(better_tweeters$screenName),]
repeat_tweeters <- rdf[duplicated(rdf$screenName),]
#fetch the user objects for Tweeters who have more followers than friends
scr_names<- repeat_tweeters$screenName
unique_tweeter_names <-unique(scr_names)
user_objects <- lookupUsers(unique_tweeter_names)
user_objects_df<-ldply(user_objects,function(t) t$toDataFrame())
curated_user_objects<- user_objects_df[(user_objects_df$followersCount>99)&(user_objects_df$followersCount/user_objects_df$friendsCount > 1),]
# save information about these curated tweeters in hashtag specific file
x <- toJSON(unname(split(curated_user_objects, 1:nrow(curated_user_objects))))
cat(x,file=hashtag_file)
curated_user_objects$followersCount
library("twitteR")
library("wordcloud")
library("tm")
library(RColorBrewer)
library(plyr)
library(rjson)
# initialization
rdf<- NULL
scr_names<-NULL
curated_user_objects <- NULL
dir <- "/Users/venuv/Desktop/WHS/Tweeter_DB"
hashtag_name <- "NCISNOLA"
hashtag_string<- paste("#",hashtag_name,sep='')
hashtag_file <- paste(dir,'/',hashtag_name,"_ht_tweeter_list.json",sep='')
## Boilerplate twitter_oauth : first time you get a prompt to cache session cookie
consumer_key <- "0IpI79mRPE3abAHrQKP8H0Z7E"
consumer_secret <- "E4EHnsQOb4BDQ7s8lTPlxWbr1guUv9F9QJBU2UmBeqwokdHJvY"
access_token <- "1202061-nzRRdJu8Ze9aEev4ZzjeORYfjvExpv6kY1Mu4RXZtB"
access_secret <- "6ElTLeMiI2JaF9NNxAUOsLZ5XyDRWJnpOXYYEEjb3RpGt"
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
## get a tweet corpus for show specific hashtag. can be regionalized to language, use ISO 639-1 code
r_show <- searchTwitter(hashtag_string,n=5000)
## retweet removal code, in case needed
#r_show_noRT<-strip_retweets(r_show)
## convert list to dataFrame for easier manipulation
rdf <- ldply(r_show,function(t) t$toDataFrame())
## filter out a curated list of tweets
# Curation Filter to be refined, but the followint at present:
#   more than avg number of retweets
#   more followers than friends
# get tweeter screen names for tweeters with more than an average number of retweets
#rtmean<-mean(rdf$retweetCount)
#better_tweeters<-rdf[rdf$retweetCount>rtmean,]
#repeat_tweeters <- better_tweeters[duplicated(better_tweeters$screenName),]
repeat_tweeters <- rdf[duplicated(rdf$screenName),]
#fetch the user objects for Tweeters who have more followers than friends
scr_names<- repeat_tweeters$screenName
unique_tweeter_names <-unique(scr_names)
user_objects <- lookupUsers(unique_tweeter_names)
user_objects_df<-ldply(user_objects,function(t) t$toDataFrame())
curated_user_objects<- user_objects_df[(user_objects_df$followersCount>99)&(user_objects_df$followersCount/user_objects_df$friendsCount > 1),]
# save information about these curated tweeters in hashtag specific file
x <- toJSON(unname(split(curated_user_objects, 1:nrow(curated_user_objects))))
cat(x,file=hashtag_file)
curated_user_objects$followersCount
names (curated_user_objects)
curated_user_objects$location
curated_user_objects$name
curated_user_objects$verified
curated_user_objects$url
curated_user_objects$lang
# initialization
rdf<- NULL
scr_names<-NULL
curated_user_objects <- NULL
# eventually, you want to accept hashtag_name and destination directory as parameters
dir <- "/Users/venuv/Desktop/WHS/Tweeter_DB"
hashtag_name <- "BigBangTheory"
hashtag_string<- paste("#",hashtag_name,sep='')
hashtag_file <- paste(dir,'/',hashtag_name,"_ht_tweeter_list.json",sep='')
## Boilerplate twitter_oauth : first time you get a prompt to cache session cookie
consumer_key <- "0IpI79mRPE3abAHrQKP8H0Z7E"
consumer_secret <- "E4EHnsQOb4BDQ7s8lTPlxWbr1guUv9F9QJBU2UmBeqwokdHJvY"
access_token <- "1202061-nzRRdJu8Ze9aEev4ZzjeORYfjvExpv6kY1Mu4RXZtB"
access_secret <- "6ElTLeMiI2JaF9NNxAUOsLZ5XyDRWJnpOXYYEEjb3RpGt"
setup_twitter_oauth(consumer_key,
consumer_secret,
access_token,
access_secret)
## get a tweet corpus for show specific hashtag. can be regionalized to language, use ISO 639-1 code
r_show <- searchTwitter(hashtag_string,n=5000)
## retweet removal code, in case needed
#r_show_noRT<-strip_retweets(r_show)
## convert list to dataFrame for easier manipulation
rdf <- ldply(r_show,function(t) t$toDataFrame())
## filter out a curated list of tweets
# Curation Filter to be refined, but the followint at present:
#   frequent tweeters (with more than one tweet in 5k corpus)
#   more followers than friends
# get tweeters with more than one tweet in corpus
#rtmean<-mean(rdf$retweetCount)
#better_tweeters<-rdf[rdf$retweetCount>rtmean,]
#repeat_tweeters <- better_tweeters[duplicated(better_tweeters$screenName),]
repeat_tweeters <- rdf[duplicated(rdf$screenName),]
# now filter out the user objects for Tweeters who have more followers than friends
# other user_object filter fields of interest : "verified", "listedCount", "location","lang"
scr_names<- repeat_tweeters$screenName
unique_tweeter_names <-unique(scr_names)
user_objects <- lookupUsers(unique_tweeter_names)
user_objects_df<-ldply(user_objects,function(t) t$toDataFrame())
curated_user_objects<- user_objects_df[(user_objects_df$followersCount>99)&(user_objects_df$followersCount/user_objects_df$friendsCount > 1),]
# save information about these curated tweeters in hashtag specific file
x <- toJSON(unname(split(curated_user_objects, 1:nrow(curated_user_objects))))
cat(x,file=hashtag_file)
$\pagebreak$
## Principle of Analytic Graphics
* **Principle 1: Show Comparisons**
* always comparative (compared to what)
* randomized trial - compare control group to test group
* evidence for a hypothesis is always relative to another competing hypothesis
* **Principle 2: Show causality/mechanism/explanation/systematic structure**
* form hypothesis to evidence showing a relationship (causal framework, why something happened)
* **Principle 3: Show multivariate data**
* more than 2 variables because the real world is multivariate
* show as much data on a plot as you can
* ***example***
```{r fig.height = 3, fig.width = 4, fig.align='center', echo=FALSE}
# install grid and png packages if not present
library(png)
library(grid)
grid.raster(readPNG("figures/1.jpg"))
```
* slightly negative relationship between pollution and mortality
* when split up by season, the relationships are all positive $\rightarrow$ season = confounding variable
```{r fig.height = 4, fig.width = 6, fig.align='center', echo=FALSE}
grid.raster(readPNG("figures/2.jpg"))
```
* **Principle 4: Integration of evidence**
* use as many modes of evidence/displaying evidence as possible (modes of data presentation)
* integrate words/numbers/images/diagrams (information rich)
* analysis should drive the tool
* **Principle 5: Describe/document evidence with appropriate labels/scales/sources**
* add credibility to that data graphic
* **Principle 6: Content is the most important**
* analytical presentations ultimately stand/fall depending on quality/relevance/integrity of content
## Exploratory Graphs ([examples](http://gallery.r-enthusiasts.com/))
* **Purpose**: understand data properties, find pattern in data, suggest modeling strategies, debug
* **Characteristics**: made quickly, large number produced, gain personal understanding, appearances and presentation are aren’t as important
### One Dimension Summary of Data
* `summary(data)` = returns min, 1st quartile, median, mean, 3rd quartile, max
* `boxplot(data, col = “blue”)` = produces a box with middles 50% highlighted in the specified color
* `whiskers` = $\pm 1.58IQR/\sqrt{n}$
* IQR = interquartile range, Q$_3$ - Q$_1$
* `box` = 25%, median, 75%
* `histograms(data, col = “green”)` = produces a histogram with specified breaks and color
* `breaks = 100` = the higher the number is the smaller/narrower the histogram columns are
* `rug(data)` =  density plot, add a strip under the histogram indicating location of each data point
* `barplot(data, col = wheat)` = produces a bar graph, usually for categorical data
* **Overlaying Features**
* `abline(h/v = 12)` = overlays horizontal/vertical line at specified location
* `col = “red”` = specifies color
* `lwd = 4` = line width
* `lty = 2` = line type
### Two Dimensional Summaries
* multiple/overlay 1D plots (using lattice/ggplot2)
* **box plots**: `boxplot(pm25 ~ region, data = pollution, col = “red”)`
```{r fig.height = 3, fig.width = 4, fig.align='center', echo=FALSE}
grid.raster(readPNG("figures/3.jpg"))
```
* **histogram**:
boxplot(pm25 ~ region, data = pollution, col = “red”)
getwd()
setwd('Desktop/useful stuff/Coursera/ExData_Plotting1/')
dir()
ls()
tbl<-read.table('household_power_consumption.txt',sep=';')
dim(tbl)
names(tbl)
head(tbl$V3)
head(tbl$V4)
hist(tbl$V3)
hist(as.numeric(tbl$V3))
hist(as.numeric(tbl$V3/1000))
hist(as.numeric(tbl$V3)/1000)
hist(as.numeric(tbl$V3)/1000,col="red")
hist(as.numeric(tbl$V3)/1000,col="red",title="Global Active Power")
hist(as.numeric(tbl$V3)/1000,col="red",main="Global Active Power")
hist(as.numeric(tbl$V3)/1000,col="red",main="Global Active Power",xlab="Global Active Power(kilowatts")
hist(as.numeric(tbl$V3)/1000,col="red",main="Global Active Power",xlab="Global Active Power(kilowatts)")
dev.copy(png,"plot1.png")
gewd()
getwd()
quarts()
quartz()
hist(as.numeric(tbl$V3)/1000,col="red",main="Global Active Power",xlab="Global Active Power(kilowatts)")
dev.copy(png,"plot1.png")
gwtwd()
getwd()
dev.copy(png,"/Users/venuv/Desktop/useful stuff/Coursera/ExData_Plotting1/plot1.png")
dev.off()
quartz()
tbl<-read.table('household_power_consumption.txt',sep=';')
hist(as.numeric(tbl$V3)/1000,col="red",main="Global Active Power",
xlab="Global Active Power(kilowatts)")
dev.copy(png,"plot1.png")
dev.off()
dev.off()
